---
description: How to send messages to agents, attach files, use MCP types, and handle responses
globs: ["**/*.py"]
alwaysApply: true
---

# Prompting Agents

**fast-agent** provides a flexible MCP based API for sending messages to agents, with convenience methods for handling Files, Prompts and Resources.

Read more about the use of MCP types in **fast-agent** [here](https://fast-agent.ai/mcp/types/).

## Sending Messages

The simplest way of sending a message to an agent is the `send` method:

```python
response: str = await agent.send("how are you?")
```

This returns the text of the agent's response as a string, making it ideal for simple interactions.

### Attaching Files

You can attach files by using `Prompt.user()` method to construct your message:

```python
from mcp_agent.core.prompt import Prompt
from pathlib import Path

plans: str = await agent.send(Prompt.user("Summarise this PDF", Path("secret-plans.pdf")))
```

`Prompt.user()` automatically converts content to the appropriate MCP Type. For example, `image/png` becomes `ImageContent` and `application/pdf` becomes an EmbeddedResource.

### Using MCP Types Directly

You can also use MCP Types directly - for example:

```python
from mcp.types import ImageContent, TextContent

mcp_text: TextContent = TextContent(type="text", text="Analyse this image.")
mcp_image: ImageContent = ImageContent(type="image", mimeType="image/png", data=base_64_encoded)

response: str = await agent.send(Prompt.user(mcp_text, mcp_image))
```

> Note: use `Prompt.assistant()` to produce messages for the `assistant` role.

## Using `generate()` and multipart content

The `generate()` method allows you to access multimodal content from an agent, or its Tool Calls as well as send conversational pairs.

```python
from mcp_agent.core.prompt import Prompt
from mcp_agent.mcp.prompt_message_multipart import PromptMessageMultipart

message = Prompt.user("Describe an image of a sunset")
response: PromptMessageMultipart = await agent.generate([message])
print(response.last_text())  # Main text response
```

The key difference between `send()` and `generate()` is that `generate()` returns a `PromptMessageMultipart` object, giving you access to the complete response structure:

- `last_text()`: Gets the last text response - usually the Assistant message without Tool Call/Response information.
- `first_text()`: Gets the first text content if multiple text blocks exist
- `all_text()`: Combines all text content in the response - including Tall Call/Response information.
- `content`: Direct access to the full list of content parts, including Images and EmbeddedResources

This is particularly useful when working with multimodal responses or tool outputs:

```python
# Generate a response that might include multiple content types
response = await agent.generate([Prompt.user("Analyze this image", Path("chart.png"))])

for content in response.content:
    if content.type == "text":
        print("Text response:", content.text[:100], "...")
    elif content.type == "image":
        print("Image content:", content.mimeType)
    elif content.type == "resource":
        print("Resource:", content.resource.uri)
```

You can also use `generate()` for multi-turn conversations by passing multiple messages:

```python
messages = [
    Prompt.user("Hello, how are you?"),
    Prompt.assistant("I'm doing well, thank you for asking!"),
    Prompt.user("Can you help me with a task?")
]

response = await agent.generate(messages)
```

## Working with Files and Resources

### File Attachments

**fast-agent** supports various file types through automatic MCP type conversion:

```python
# PDF files
pdf_response = await agent.send(Prompt.user("Summarize this document", Path("document.pdf")))

# Image files
image_response = await agent.send(Prompt.user("Describe this image", Path("photo.jpg")))

# Text files
text_response = await agent.send(Prompt.user("Analyze this code", Path("script.py")))
```

### Multiple Files

You can attach multiple files in a single message:

```python
response = await agent.send(Prompt.user(
    "Compare these two documents",
    Path("document1.pdf"),
    Path("document2.pdf")
))
```

### URL Resources

You can also reference remote resources:

```python
from mcp.types import Resource

resource = Resource(uri="https://example.com/data.json", mimeType="application/json")
response = await agent.send(Prompt.user("Analyze this data", resource))
```

## Structured Outputs

**fast-agent** supports structured outputs using Pydantic models:

```python
from pydantic import BaseModel
from typing import List

class AnalysisResult(BaseModel):
    summary: str
    key_points: List[str]
    confidence: float

# Send a message and get structured response
result: AnalysisResult = await agent.structured(
    "Analyze this document and provide a structured summary",
    AnalysisResult,
    Path("document.pdf")
)

print(f"Summary: {result.summary}")
print(f"Key points: {result.key_points}")
print(f"Confidence: {result.confidence}")
```

## Tool Calls and Responses

When agents use MCP tools, you can access the tool calls and responses:

```python
response = await agent.generate([Prompt.user("Search for information about Python")])

# Access tool calls
for content in response.content:
    if hasattr(content, 'toolCalls'):
        for tool_call in content.toolCalls:
            print(f"Tool called: {tool_call.name}")
            print(f"Arguments: {tool_call.arguments}")
    
    if hasattr(content, 'toolResults'):
        for tool_result in content.toolResults:
            print(f"Tool result: {tool_result.content}")
```

## Conversation History

### Accessing History

You can access the conversation history of an agent:

```python
# Get the full conversation history
history = agent.agent_name.message_history

# Get history as PromptMessageMultipart objects
for message in history:
    if message.role == "user":
        print("User:", message.content[0].text)
    elif message.role == "assistant":
        print("Assistant:", message.content[0].text)
```

### Transferring History

You can transfer conversation history between agents:

```python
# Transfer history from one agent to another
agent.agent_two.generate(agent.agent_one.message_history)

# Continue conversation with transferred context
response = await agent.agent_two.send("Continue from where we left off")
```

## Advanced Prompting Techniques

### Template Variables

You can use template variables in your prompts:

```python
from mcp_agent.core.prompt import Prompt

template = Prompt.user("Hello {{name}}, how can I help you with {{topic}}?")
response = await agent.send(template, name="Alice", topic="Python programming")
```

### Conditional Content

You can conditionally include content based on context:

```python
def create_prompt(user_input: str, include_context: bool = False):
    if include_context:
        return Prompt.user(
            "Given this context: {{context}}, respond to: {{input}}",
            context="Additional background information",
            input=user_input
        )
    else:
        return Prompt.user(user_input)

response = await agent.send(create_prompt("What is AI?", include_context=True))
```

## Error Handling

### Handling Tool Errors

When tools fail, you can handle the errors gracefully:

```python
try:
    response = await agent.send("Search for information about a topic")
except ToolCallError as e:
    print(f"Tool call failed: {e.tool_name}")
    print(f"Error: {e.error}")
    # Handle the error appropriately
```

### Handling Model Errors

```python
try:
    response = await agent.send("Generate a response")
except ModelError as e:
    print(f"Model error: {e.message}")
    # Retry with different parameters or handle gracefully
```

## Best Practices

### Message Construction

1. **Use appropriate MCP types** for different content types
2. **Keep messages concise** but informative
3. **Use structured outputs** for predictable responses
4. **Handle errors gracefully** in production applications

### Performance Optimization

1. **Batch operations** when possible
2. **Use appropriate models** for different tasks
3. **Cache responses** for repeated queries
4. **Monitor token usage** for cost optimization

### Security Considerations

1. **Validate file inputs** before sending to agents
2. **Sanitize user inputs** to prevent injection attacks
3. **Use appropriate authentication** for sensitive operations
4. **Log interactions** for audit purposes

---

*Source: [https://fast-agent.ai/agents/prompting/](https://fast-agent.ai/agents/prompting/)*
